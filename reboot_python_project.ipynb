{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание для проекта Reboot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.\tВыгрузить описания открытых вакансий с любой из площадок (hh.ru, rabota.sber.ru, indeed.com) или воспользоваться готовой выгрузкой ... \n",
    "\n",
    "2.\t<a href=\"https://python-school.ru/nlp-text-preprocessing/\">Предообработать</a> текст описаний вакансий.\n",
    "    * очистить текст -  убрать лишние символы и html-тэги\n",
    "    * привести к одному регистру\n",
    "    * токенизировать - разбить текст на слова\n",
    "    * удалить часто встречающиеся слова и стоп-слова\n",
    "    * <a href=\"https://pymorphy2.readthedocs.io/en/stable/\"> нормировать  </a>(красивые машины -> красивый машина) <br>\n",
    "    подробнее про обработку естественного языка (NLP) можно прочитать <a href=\"https://neerc.ifmo.ru/wiki/index.php?title=Обработка_естественного_языка\">здесь<a>)\n",
    "3.\tВзять любой текст, описывающий опыт из резюме и аналогично предобработать.\n",
    "4.\tПосчитать векторное представление описаний вакансий и опыта из резюме.\n",
    "    * для того чтобы обрабатывать текстовые данные с помощью методов машинного обучения текст преобразуют в векторное представление или эмбеденги. \n",
    "    * для того чтобы преобразовать слова или предложения в эмбедениг используют разные алгоритмы (<a href=\"https://habr.com/ru/company/Voximplant/blog/446738/\" > TF-IDF</a>, Word2Vec, <a href=\"https://fasttext.cc/docs/en/support.html\"> Fasttext</a>, Bert и другие)\n",
    "    \n",
    "5.\tПосчитать косинусную меру сходства для опыта и описаний вакансий. Подробнее о об этом  <a href=\"https://ru.wikipedia.org/wiki/Векторная_модель#.D0.9A.D0.BE.D1.81.D0.B8.D0.BD.D1.83.D1.81.D0.BD.D0.BE.D0.B5_.D1.81.D1.85.D0.BE.D0.B4.D1.81.D1.82.D0.B2.D0.BE\"> здесь</a> и <a href=\"http://zabaykin.ru/?p=737\"> здесь</a> \n",
    "6.\tРанжировать вакансии по мере их сходства с опытом и вывести Топ-10 наиболее релевантных вакансий\n",
    "7.\tПодготовить скрипт принимающий на вход текстовое описание опыта и выводящий Топ-10 наиболее релевантных вакансий из всех или 100 случайно выбранных из выгрузки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Проверка будет проходить в формате api, который принимает на вход строку текста, а в ответ возвращает топ-10 вакансий. Пример в приложенном скрипте сделан с помощью фреймворка  <a href=\"https://fastapi.tiangolo.com/\">FastAPI</a>. \n",
    "* Проверить результат работы можно запустив сервис с помощью команды <b> uvicorn main:app --reload </b> и затем отправив соответствующий запрос либо с помощью встроенного сервиса http://127.0.0.1:8000/docs, либо с помощью Postman\n",
    "* Шаблон для API указан в приложении\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Выгружаем описания вакансий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.field_size_limit(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacs = pd.read_csv('vacancy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4002, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacs.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.Предобрабатываем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>vacid</th>\n",
       "      <th>vactitle</th>\n",
       "      <th>vacdescription</th>\n",
       "      <th>vacdate</th>\n",
       "      <th>vacstatus</th>\n",
       "      <th>vaclink</th>\n",
       "      <th>vachtml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>383479</td>\n",
       "      <td>2021-03-14 09:39:21.854462</td>\n",
       "      <td>2021-03-14 09:39:21.854584</td>\n",
       "      <td>1474941</td>\n",
       "      <td>Senior java-разработчик (в команду Онбординга)</td>\n",
       "      <td>Работа у нас — это:команда профессионалов, го...</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>new</td>\n",
       "      <td>https://my.sbertalents.ru/#/job-requisition/14...</td>\n",
       "      <td>{\"title\": \"Senior java-\\u0440\\u0430\\u0437\\u044...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                  created_at                  updated_at    vacid  \\\n",
       "0  383479  2021-03-14 09:39:21.854462  2021-03-14 09:39:21.854584  1474941   \n",
       "\n",
       "                                         vactitle  \\\n",
       "0  Senior java-разработчик (в команду Онбординга)   \n",
       "\n",
       "                                      vacdescription     vacdate vacstatus  \\\n",
       "0   Работа у нас — это:команда профессионалов, го...  2021-03-15       new   \n",
       "\n",
       "                                             vaclink  \\\n",
       "0  https://my.sbertalents.ru/#/job-requisition/14...   \n",
       "\n",
       "                                             vachtml  \n",
       "0  {\"title\": \"Senior java-\\u0440\\u0430\\u0437\\u044...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция удаления пунктуации и цифр\n",
    "def remove_trash(x): \n",
    "    desc = list(x)\n",
    "    description_result = []\n",
    "    for i in desc:\n",
    "        i = str(i)\n",
    "        y = re.sub(r'[^А-Яа-яЁё ]+', ' ', i)\n",
    "        description_result.append(y)\n",
    "    return description_result\n",
    "\n",
    "vacs['vacdesc_clean'] = remove_trash(vacs['vacdescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Условия    работа в крупнейшем банке России  трудоустройство согласно ТК РФ  регулярное корпоративное обучение  ДМС  страхование от несчастных случаев и тяжелых заболеваний  материальная помощь и социальная поддержка  корпоративная пенсионная программа  льготные условия кредитования  яркая и насыщенная корпоративная жизнь  Обязанности    контроль и проверка работоспособности систем безопасности  в т ч  автоматизированных  на закрепленных объектах   ОПС  контроль доступа  телевизионная система наблюдения  проведение проверочных мероприятий по своему направлению согласно инструкциям  в том числе в отношении кандидатов  осуществление мер по защите объекта  жизни и здоровья сотрудников и клиентов при обнаружении инцидентов  анализ информации  полученной в результате проверок  формирование первичных выводов  формирование справок  отчётности и заключений по своему направлению для руководителей  подготовка материалов для составления ТЗ по разработке проектно сметной документации по конкретной автоматизированной системе  предоставление коллегам  посетителям и или клиентам Банка справочно информационных услуг по своему направлению  контроль работы и инструктаж для коллег   Требования    высшее образование  техническое радиотехника  электроника  системы безопасности  опыт работы по монтажу  обслуживанию  ремонту электронных систем безопасности или организации данной работы от   года  знание электронных систем безопасности  систем видеомониторинга  систем оповещения  систем контроля и управления доступом  готовность к выездной работе  наличие личного автомобиля  затраты компенсируются    опытный пользователь ПК  опыт работы с офисными приложениями  коммуникабельность  исполнительность  стрессоустойчивость      высшее образование  техническое радиотехника  электроника  системы безопасности  опыт работы по монтажу  обслуживанию  ремонту электронных систем безопасности или организации данной работы от   года  знание электронных систем безопасности  систем видеомониторинга  систем оповещения  систем контроля и управления доступом  готовность к выездной работе  наличие личного автомобиля  затраты компенсируются    опытный пользователь ПК  опыт работы с офисными приложениями  коммуникабельность  исполнительность  стрессоустойчивость      контроль и проверка работоспособности систем безопасности  в т ч  автоматизированных  на закрепленных объектах   ОПС  контроль доступа  телевизионная система наблюдения  проведение проверочных мероприятий по своему направлению согласно инструкциям  в том числе в отношении кандидатов  осуществление мер по защите объекта  жизни и здоровья сотрудников и клиентов при обнаружении инцидентов  анализ информации  полученной в результате проверок  формирование первичных выводов  формирование справок  отчётности и заключений по своему направлению для руководителей  подготовка материалов для составления ТЗ по разработке проектно сметной документации по конкретной автоматизированной системе  предоставление коллегам  посетителям и или клиентам Банка справочно информационных услуг по своему направлению  контроль работы и инструктаж для коллег       работа в крупнейшем банке России  трудоустройство согласно ТК РФ  регулярное корпоративное обучение  ДМС  страхование от несчастных случаев и тяжелых заболеваний  материальная помощь и социальная поддержка  корпоративная пенсионная программа  льготные условия кредитования  яркая и насыщенная корпоративная жизнь  '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacs['vacdesc_clean'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "Collecting docopt>=0.6\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13709 sha256=7c38427b34fdec53af152991926ccca612b3711752bedb223fb9d400e3a25bb6\n",
      "  Stored in directory: c:\\users\\zhenya\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-195c9738961c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mvacs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vacdesc_morphed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvacs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6877\u001b[0m         )\n\u001b[1;32m-> 6878\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6880\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 result = libreduction.compute_reduction(\n\u001b[0m\u001b[0;32m    296\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m                 )\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-99-195c9738961c>\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmorph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_form\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymorphy2\\analyzer.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_terminal\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_lower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_terminal\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymorphy2\\units\\by_lookup.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, word, word_lower, seen_parses)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \"\"\"\n\u001b[0;32m     23\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mpara_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilar_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_lower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar_substitutes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfixed_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparses\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpara_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dawg_python\\dawgs.py\u001b[0m in \u001b[0;36msimilar_items\u001b[1;34m(self, key, replaces)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0municode\u001b[0m \u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \"\"\"\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_similar_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mROOT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dawg_python\\dawgs.py\u001b[0m in \u001b[0;36m_similar_items\u001b[1;34m(self, current_prefix, key, index, replace_chars)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                 \u001b[0mfound_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_pos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_for_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfound_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dawg_python\\dawgs.py\u001b[0m in \u001b[0;36m_value_for_index\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_for_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRecordDAWG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_for_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_struct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dawg_python\\dawgs.py\u001b[0m in \u001b[0;36m_value_for_index\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mcompleter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0mcompleter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m             \u001b[1;31m# a2b_base64 doesn't support bytearray in python 2.6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;31m# so it is converted (and copied) to bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dawg_python\\wrapper.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_terminal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_follow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dawg_python\\wrapper.py\u001b[0m in \u001b[0;36m_find_terminal\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_stack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# функция лемматизации\n",
    "def lemmatize(row):\n",
    "    t = []\n",
    "    text = row['vacdesc_clean']\n",
    "    for word in text.split():\n",
    "        if len(word)<=3:\n",
    "            continue\n",
    "        p = morph.parse(word)[0]\n",
    "        t.append(p.normal_form)\n",
    "    return \" \".join(t)\n",
    "\n",
    "\n",
    "vacs['vacdesc_morphed'] = vacs.apply(lemmatize, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ZHENYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       работа команда профессионал готовый поддержать...\n",
       "1       искать дизайнер наш дружный команда сбербанк н...\n",
       "2       условие официальный трудоустройство дневный ра...\n",
       "3       блок риск стартовать программа миграция фабрик...\n",
       "4       работа работа крупный банк россия команда проф...\n",
       "                              ...                        \n",
       "3997    система статический динамический анализ исходн...\n",
       "3998    аналитика проведение служебный расследование с...\n",
       "3999    условие работа крупный центр киберзащита стран...\n",
       "4000    продукт защита периметр защита атака защита пр...\n",
       "4001    предлагать оформление согласно трудовой кодекс...\n",
       "Name: vacdesc_morphed, Length: 4002, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacs['vacdesc_morphed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacs.to_csv('vacancy_morphed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_russian = stopwords.words('russian')\n",
    "text_transformer = TfidfVectorizer(stop_words=stop_russian, ngram_range=(1, 1), lowercase=True, max_features=15000)\n",
    "text = text_transformer.fit_transform(vacs['vacdesc_morphed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Взять любой текст, описывающий опыт из резюме и аналогично предобработать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = open('CV_description_simplified.txt', 'r', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_exp = CV.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'• Анализ данных, составление отчётности, графиков, диаграмм, презентаций;\\n• Работа с большими массивами данных в Excel и Access, использование функций массивов, ВПР, сводных таблиц, работа с макросами (VBA, на уровне чтения и частичной корректировки);\\n• Разработка и согласование Планов развития и инвестиций с использованием методов регрессионного анализа.\\n• Руководство командой аналитиков\\n• Написание функциональных требований и согласование технических заданий к внутренним информационным системам\\n• Работа с BI-аналитикой (определение исходных данных, проектирование структуры отчётов)\\n'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_exp_cleaned = re.sub(r'[^А-Яа-яЁё ]+', ' ', str(cv_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(row):\n",
    "    t = []\n",
    "    text = row\n",
    "    for word in text.split():\n",
    "        if len(word)<=3:\n",
    "            continue\n",
    "        p = morph.parse(word)[0]\n",
    "        t.append(p.normal_form)\n",
    "    return \" \".join(t)\n",
    "cv_morphed = lemmatize(cv_exp_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'анализ данные составление отчётность график диаграмма презентация работа больший массив данные использование функция массив сводный таблица работа макрос уровень чтение частичный корректировка разработка согласование план развитие инвестиция использование метод регрессионный анализ руководство команда аналитик написание функциональный требование согласование технический задание внутренний информационный система работа аналитика определение исходный данные проектирование структура отчёт'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_morphed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ready_tf_idf = pd.DataFrame([cv_morphed])\n",
    "cv_ready_tf_idf.columns = ['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Посчитать векторное представление описаний вакансий и опыта из резюме.\n",
    "## 5. Посчитать косинусную меру сходства для опыта и описаний вакансий\n",
    "## 6. Вывести Топ-10 наиболее релевантных вакансий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4002x12091 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 448992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text #вектор вакансий, из пункта 2, просто для памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cv = text_transformer.transform(cv_ready_tf_idf['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x12091 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 43 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = linear_kernel(text_cv, text).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacs['cos_similarities'] = cosine_similarities\n",
    "# и отсортируем по убыванию (т.к. cos(0)=1)\n",
    "vacs = vacs.sort_values(by=['cos_similarities'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Практикант 0.31606967550200676\n",
      "Старший эксперт по технологиям 0.27730824460857545\n",
      "Администратор проекта/delivery-менеджер 0.27534279893690683\n",
      "Senior QA инженер 0.26954310921685964\n",
      "Консультант по работе с ПФР 0.26210848775198553\n",
      "Менеджер по продажам 0.24351257369148158\n",
      "DevOps Инженер 0.24175156143823462\n",
      "Старший менеджер по обслуживанию 0.2379008527334487\n",
      "Кассир 0.23789559691072196\n",
      "Региональный менеджер (Супер-коуч) 0.23652843351749347\n"
     ]
    }
   ],
   "source": [
    "# Выведем 10 самых близких результатов\n",
    "for index, row in vacs[0:10].iterrows():\n",
    "    print(row['vactitle'], row['cos_similarities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для полной версии резюме результат:\n",
    "\n",
    "Старший специалист по взысканию задолженности 0.29592914800589193\n",
    "Ведущий специалист по взысканию 0.28416383394748446\n",
    "Старший менеджер по обслуживанию 0.2798215626064644\n",
    "Практикант (г. Челябинск) 0.27439373829957875\n",
    "Руководитель проектов (Кластер \"Управление ценой и доходностью\") 0.27057265234994626\n",
    "Ведущий специалист по взысканию 0.2585420788919523\n",
    "Специалист по прямым продажа 0.25748112929621153\n",
    "Главный специалист по проблемным активам крупного и среднего бизнеса 0.2553456849490878\n",
    "Инженер (DevOps) 0.2531196995932508\n",
    "Специалист по прямым продажам 0.24942572925356413"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
